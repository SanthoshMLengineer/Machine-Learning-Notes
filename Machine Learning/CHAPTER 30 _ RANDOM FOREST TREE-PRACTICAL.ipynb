{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1294,"status":"ok","timestamp":1667300891320,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"8GjITwqgbknS"},"outputs":[],"source":["# Importing the required Package\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn import datasets\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score,confusion_matrix\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import KFold\n","\n","import statistics\n","\n","import numpy as np\n","\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":78,"status":"ok","timestamp":1667300891328,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"zQzKPtjRbknd"},"outputs":[],"source":["# Load data\n","iris = datasets.load_iris()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1667300891331,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"2sAvCYTNbkni","outputId":"35c73a10-4b86-4f98-98d8-6a542d465646"},"outputs":[{"output_type":"stream","name":"stdout","text":[".. _iris_dataset:\n","\n","Iris plants dataset\n","--------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 150 (50 in each of three classes)\n","    :Number of Attributes: 4 numeric, predictive attributes and the class\n","    :Attribute Information:\n","        - sepal length in cm\n","        - sepal width in cm\n","        - petal length in cm\n","        - petal width in cm\n","        - class:\n","                - Iris-Setosa\n","                - Iris-Versicolour\n","                - Iris-Virginica\n","                \n","    :Summary Statistics:\n","\n","    ============== ==== ==== ======= ===== ====================\n","                    Min  Max   Mean    SD   Class Correlation\n","    ============== ==== ==== ======= ===== ====================\n","    sepal length:   4.3  7.9   5.84   0.83    0.7826\n","    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n","    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n","    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n","    ============== ==== ==== ======= ===== ====================\n","\n","    :Missing Attribute Values: None\n","    :Class Distribution: 33.3% for each of 3 classes.\n","    :Creator: R.A. Fisher\n","    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n","    :Date: July, 1988\n","\n","The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n","from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n","Machine Learning Repository, which has two wrong data points.\n","\n","This is perhaps the best known database to be found in the\n","pattern recognition literature.  Fisher's paper is a classic in the field and\n","is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n","data set contains 3 classes of 50 instances each, where each class refers to a\n","type of iris plant.  One class is linearly separable from the other 2; the\n","latter are NOT linearly separable from each other.\n","\n",".. topic:: References\n","\n","   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n","     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n","     Mathematical Statistics\" (John Wiley, NY, 1950).\n","   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n","     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n","   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n","     Structure and Classification Rule for Recognition in Partially Exposed\n","     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n","     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n","   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n","     on Information Theory, May 1972, 431-433.\n","   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n","     conceptual clustering system finds 3 classes in the data.\n","   - Many, many more ...\n"]}],"source":["# Description About data set\n","print(iris.DESCR)\n","\n","# After seeing below we need to build a model for classifying the classes of iris, so it is classification Problem."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":52,"status":"ok","timestamp":1667300891333,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"dcFXCTDPbknl"},"outputs":[],"source":["# Training Data\n","X = pd.DataFrame(iris.data,columns = iris.feature_names)\n","\n","# Testing Data\n","y = pd.DataFrame(iris.target,columns = ['species'])"]},{"cell_type":"markdown","metadata":{"id":"e5AXl1pPbknp"},"source":["<h3>K-Fold Cross Validation</h3>"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1299,"status":"ok","timestamp":1667300892594,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"V71VFlLmbknt"},"outputs":[],"source":["kf = KFold(n_splits=10)\n","\n","k_fold_score = []\n","for train_index, test_index in kf.split(X,y):\n","    \n","    # print(X.iloc[list(train_index),:])\n","    \n","    X_train, X_test = X.iloc[list(train_index),:], X.iloc[list(test_index),:]\n","    y_train, y_test = y.iloc[list(train_index),:], y.iloc[list(test_index),:]\n","    \n","    model = RandomForestClassifier()\n","    model.fit(X_train,y_train)\n","    y_predict = model.predict(X_test)\n","    k_fold_score.append(accuracy_score(y_test,y_predict))\n","   "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1667300892600,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"w4rvSfbnbknx","outputId":"3eb0ab96-2795-421f-c1e7-29599700cf40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Minimum accuracy we get is 0.8\n","Maximun accuracy we get is 1.0\n","We can get average accuracy is 0.9466666666666667\n"]}],"source":["print(\"Minimum accuracy we get is {}\".format(min(k_fold_score)))\n","print(\"Maximun accuracy we get is {}\".format(max(k_fold_score)))\n","print(\"We can get average accuracy is {}\".format(statistics.mean(k_fold_score)))"]},{"cell_type":"markdown","metadata":{"id":"awkvzMIzbkn1"},"source":["<h3>Stratified K Fold Cross Validation</h3>"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1349,"status":"ok","timestamp":1667300893909,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"N3e6bz8Ibkn4"},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=10)\n","\n","Stratified_score = []\n","for train_index, test_index in skf.split(X, y):\n","    \n","    X_train, X_test = X.iloc[list(train_index),:], X.iloc[list(test_index),:]\n","    y_train, y_test = y.iloc[list(train_index),:], y.iloc[list(test_index),:]\n","    \n","    model = RandomForestClassifier()\n","    model.fit(X_train,y_train)\n","    y_predict = model.predict(X_test)\n","    Stratified_score.append(accuracy_score(y_test,y_predict))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1667300893911,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"d0T-LiWvbkn7","outputId":"4bc5a96c-d7e4-4d4c-9068-5df31a07b519"},"outputs":[{"output_type":"stream","name":"stdout","text":["Minimum accuracy we get is 0.8666666666666667\n","Maximun accuracy we get is 1.0\n","We can get average accuracy is 0.96\n"]}],"source":["print(\"Minimum accuracy we get is {}\".format(min(Stratified_score)))\n","print(\"Maximun accuracy we get is {}\".format(max(Stratified_score)))\n","print(\"We can get average accuracy is {}\".format(\n","    statistics.mean(Stratified_score)))"]},{"cell_type":"markdown","metadata":{"id":"1FOolsfsbmRv"},"source":["**<center><h1>Parameter Tunning</h1></center>**"]},{"cell_type":"markdown","metadata":{"id":"wxQwluCBbmRz"},"source":["**Parameters**\n","\n","1. **n_estimators:**\n","  \n","  It defines the number of decision trees to be created in a random forest.\n","Generally, a higher number makes the predictions stronger and more stable, but a very large number can result in higher training time.\n","2. **criterion:**\n","\n","  It defines the function that is to be used for splitting.\n","The function measures the quality of a split for each feature and chooses the best split.\n","3. **max_features:**\n","\n","  It defines the maximum number of features allowed for the split in each decision tree.\n","Increasing max features usually improve performance but a very high number can decrease the diversity of each tree.\n","4. **max_depth:**\n","\n","  Random forest has multiple decision trees. This parameter defines the maximum depth of the trees.\n","5. **min_samples_split:**\n","\n","  Used to define the minimum number of samples required in a leaf node before a split is attempted.\n","If the number of samples is less than the required number, the node is not split.\n","6. **min_samples_leaf:**\n","\n","  This defines the minimum number of samples required to be at a leaf node.\n","Smaller leaf size makes the model more prone to capturing noise in train data.\n","7. **max_leaf_nodes:**\n","\n","  This parameter specifies the maximum number of leaf nodes for each tree.\n","The tree stops splitting when the number of leaf nodes becomes equal to the max leaf node.\n","8. **n_jobs:**\n","\n","  This indicates the number of jobs to run in parallel.\n","Set value to -1 if you want it to run on all cores in the system.\n","9. **random_state:**\n","\n","  This parameter is used to define the random selection.\n","It is used for comparison between various models.\n"]},{"cell_type":"markdown","metadata":{"id":"kWoJXspPbmR3"},"source":["We will try adjusting the following set of hyperparameters:\n","\n","- n_estimators: Number of trees in the foreset\n","- max_features: Max number of features considered for splitting a node\n","- max_depth: Max number of levels in each decision tree\n","- min_samples_split: Min number of data points placed in a node before the node is split\n","- min_samples_leaf: Min number of data points allowed in a leaf node\n","- bootstrap: Method for sampling data points (with or without replacement)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1153,"status":"ok","timestamp":1667300895044,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"},"user_tz":-330},"id":"5h_sAT_hbmR8","outputId":"77b3394e-490d-4e98-9f69-654ab7cabf3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"]}],"source":["# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n","\n","# Number of features to consider at every split\n","max_features = ['auto', 'sqrt']\n","\n","# Maximum number of levels in tree\n","max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","max_depth.append(None)\n","\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10]\n","\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = [1, 2, 4]\n","\n","# Method of selecting samples for training each tree\n","bootstrap = [True, False]\n","\n","# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf,\n","               'bootstrap': bootstrap}\n","print(random_grid)"]},{"cell_type":"markdown","metadata":{"id":"52Ga9FvSj69R"},"source":["<u>Randomised search</u>"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wSJVETjbmSS","executionInfo":{"status":"ok","timestamp":1667301410025,"user_tz":-330,"elapsed":515008,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"}},"outputId":"af8ac844-5296-4013-bee0-cd4ec212f871"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False}\n"]}],"source":["random_search = RandomizedSearchCV(RandomForestClassifier(), \n","                                   random_grid, \n","                                   random_state=1, \n","                                   n_iter=100, \n","                                   cv=5, \n","                                   verbose=0, \n","                                   n_jobs=-1)\n","\n","random_search.fit(X_train,y_train)\n","\n","#Print The value of best Hyperparameters\n","print(random_search.best_params_)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rD0VLqYqbmSZ","executionInfo":{"status":"ok","timestamp":1667301411237,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Santhosh Kumar","userId":"02779163303914785334"}},"outputId":"b8260c46-fb54-4886-f756-5a447efdd449"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of random forest tree model for classifying iris species 1.0\n"]}],"source":["X_train,X_test,y_train,y_test = train_test_split(X,y,\n","                                                 test_size=0.2,\n","                                                 random_state=10)\n","model = RandomForestClassifier(n_estimators =  1400, \n","                               min_samples_split =  10, \n","                               min_samples_leaf =  2, \n","                               max_features = 'auto', \n","                               max_depth =  40, \n","                               bootstrap =  False)\n","model.fit(X_train,y_train)\n","\n","y_predict = model.predict(X_test)\n","y_proba = model.predict_proba(X_test)\n","print(\"Accuracy of random forest tree model for classifying iris species\",\n","      accuracy_score(y_test,y_predict))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyOxyFAWsT3nDLXu9uc1r3DS"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}