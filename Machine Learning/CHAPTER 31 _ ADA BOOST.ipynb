{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOGT0PqllvmBZl2zefNBgOW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**<h1><center>ADA BOOST</center></h1>**\n","\n","Adaptive boosting or AdaBoost is one of the simplest boosting algorithms. Usually, decision trees are used for modelling. Multiple sequential models are created, each correcting the errors from the last model. AdaBoost assigns weights to the observations which are incorrectly predicted and the subsequent model works to predict these values correctly.\n","\n","\n","\n","<u>steps for performing the AdaBoost algorithm:</u>\n","\n","1. **<u>Creating First Base Learner :</u>** In ADA boost, decision tree will have only one split called decision stumps.\n","\n","\n","\n","  Let us assume one example dataset:  \n","  ```\n","            ---  ---  ---  ------  -------------\n","            F1   F2   F3   Target  Sample Weight\n","            ---  ---  ---  ------  -------------\n","            1    2    4    YES         1/4\n","            ---  ---  ---  -----   -------------\n","            2    4    8    NO          1/4\n","            ---  ---  ---  -----   -------------\n","            3    6    12   YES         1/4\n","            ---  ---  ---  -----   -------------\n","            4    8    16   NO          1/4\n","            ---  ---  ---  ----    -------------\n","  ```\n","  For each data point equal weight will assaigned. We have four data points then weight is 1/4. \n","\n","  For each feature calculate `gini` which feature gives low value will be consider that feature to create decision stump.\n","\n","2. **<u>Calculate Total Error and performance of model : </u>**\n","\n","  Total Error is  sum of all the errors in the classified record for sample weights.. Let us assume their is one misclassified from the model then their is one error. So total error is 1/4. \n","\n","  Performance = 1/2 log e (1-Total Error / Total Error)\n","\n","       Here from example TE = 1/4        \n","               = 1/2 loge(1-1/4 / 1/4)\n","               = 1/2 loge (3)\n","               = o.5 * 1.098612\n","               = 0.549306\n","\n","  The new weight should be updated for each datapoint. \n","\n","  ```\n","  New weight for misclassified record is = Sample Weight * e^(Performance) \n","\n","  = 1/4 * e ^ 0.549306\n","  \n","  = 1/4 * 1.73205055757\n","  \n","  = 0.25 * 1.73205055757\n","  \n","  = 0.43301263939\n","  ```\n","  ```\n","  New weight for correctly classified record is = \n","  Sample Weight * e^-(Performance) \n","\n","  = 1/4 * 0.57735035252\n","  \n","  = 0.25 * 0.57735035252\n","  \n","  = 0.14433758813\n","  ```\n","\n","  ```\n","  Then updated weight will be\n","  ---  ---  ---  ------  -------------  ---------------\n","  F1   F2   F3   Target  Sample Weight   Updated Weight\n","  ---  ---  ---  ------  -------------  ---------------\n","  1    2    4     YES         1/4         0.43301263939\n","  ---  ---  ---  -----   -------------  ---------------\n","  2    4    8     NO          1/4         0.14433758813\n","  ---  ---  ---  -----   -------------  ---------------\n","  3    6    12    YES         1/4         0.14433758813\n","  ---  ---  ---  -----   -------------  ---------------\n","  4    8    16    NO          1/4         0.14433758813\n","  ---  ---  ---  ----    -------------  ---------------\n","\n","  If we sum updated weight column it does not give 1 then we need normalised it to make it 1. \n","\n","  Normalised weight =  weight / Total weight of updated weight\n","\n","  ---  ---  ---  ------  -------------  ---------------  ------------------\n","  F1   F2   F3   Target  Sample Weight   Updated Weight  Normalised weight\n","  ---  ---  ---  ------  -------------  ---------------  ------------------\n","  1    2    4    YES         1/4         0.43301263939  0.49999992783\n","  ---  ---  ---  -----   -------------  ---------------  ------------------\n","  2    4    8    NO          1/4         0.14433758813  0.16666669072\n","  ---  ---  ---  -----   -------------  ---------------  ------------------\n","  3    6    12  YES         1/4         0.14433758813  0.16666669072\n","  ---  ---  ---  -----   -------------  ---------------  -----------------\n","  4    8    16   NO          1/4         0.14433758813  0.16666669072\n","  ---  ---  ---  ----    -------------  ---------------  -----------------\n","  ```\n","\n","3. **<u>Create New Dataset</u>**:\n","  \n","  To make a new dataset based on normalized weight, the algorithm will divide it into buckets.\n","\n","  ```\n","  ------------------   --------------------------------\n","  Normalised weight      Buckets\n","  ------------------   --------------------------------\n","  0.49999992783          0 - 0.49999992783\n","  ------------------   --------------------------------\n","  0.16666669072          0.49999992783 - 0.66666661855\n","  ------------------   --------------------------------\n","  0.16666669072          0.66666661855 - 0.83333330927\n","  -----------------    --------------------------------\n","  0.16666669072          0.83333330927 - 0.99999999999\n","  -----------------\n","  ```\n","\n","  Algorithm will run 4 iterations to select different records from the older dataset. Suppose in the 1st iteration, the algorithm will take a random value 0.46 to see which bucket that value falls into and select that record in the new dataset. It will again select a random value, see which bucket it is in and select that record for the new dataset. The same process is repeated 4 times. \n","\n","  There is a high probability for wrong records to get selected several times. \n","  ```\n","  ---  ---  ---  ------  -------------  ---------------  ------------------\n","  F1   F2   F3   Target  Sample Weight   Updated Weight  Normalised weight\n","  ---  ---  ---  ------  -------------  ---------------  ------------------\n","  1    2    4    YES         1/4         0.43301263939  0.49999992783\n","  ---  ---  ---  -----   -------------  ---------------  ------------------\n","  2    4    8     NO          1/4         0.14433758813  0.16666669072\n","  ---  ---  ---  -----   -------------  ---------------  ------------------\n","  1    2    4    YES         1/4         0.14433758813  0.16666669072\n","  ---  ---  ---  -----   -------------  ---------------  -----------------\n","  1    2    4    YES          1/4         0.14433758813  0.16666669072\n","  ---  ---  ---  ----    -------------  ---------------  -----------------\n","  ```\n","\n","  Based on this new dataset, the algorithm will create a new decision tree/stump trained and same procedure is repeated.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Wr0jh22-57Ab"}}]}